<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inteligencia artificial on Blog</title>
    <link>http://localhost:4321/tags/inteligencia-artificial/</link>
    <description>Recent content in Inteligencia artificial on Blog</description>
    <generator>Hugo</generator>
    <language>es-ES</language>
    <lastBuildDate>Sun, 22 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:4321/tags/inteligencia-artificial/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Análisis de sentimiento usando modelos de lenguaje (LLM) locales en R</title>
      <link>http://localhost:4321/blog/analisis_sentimiento_llm/</link>
      <pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/analisis_sentimiento_llm/</guid>
      <description>&lt;p&gt;El análisis de sentimientos es una técnica de análisis de texto donde se aplican distintos algoritmos para poder clasificar textos de distinta longitud y complejidad en un conjunto preestablecido de categorías relacionadas al sentimiento de dichos textos. Con el &lt;em&gt;sentimiento&lt;/em&gt; de los textos nos referimos a la información subjetiva que entregan estos textos, así como los afectos que producen. Por ejemplo, &amp;ldquo;odio a mi gato&amp;rdquo; versus &amp;ldquo;mi gatita es tan tierna&amp;rdquo; son dos textos que expresan distintos niveles de negatividad/positividad, agresividad, ternura, etcétera. Las categorías del análisis del sentimiento suelen ser &lt;em&gt;positivo, neutro&lt;/em&gt; y &lt;em&gt;negativo,&lt;/em&gt; u otras más complejas, como agrado (agradable/desagradable), activación (activo/pasivo), entre otros.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Procesando datos de texto en masa usando modelos de lenguaje (LLM)</title>
      <link>http://localhost:4321/blog/2024-12-20/</link>
      <pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/2024-12-20/</guid>
      <description>&lt;p&gt;Anoche dejé el computador procesando 5000 noticias por 8 horas usando un modelo de lenguaje (LLM) local en R para obtener clasificación, resumen y sentimiento de cada texto.&lt;/p&gt;&#xA;&lt;p&gt;Esto porque tengo una &#xA;&lt;a href=&#34;https://github.com/bastianolea/prensa_chile&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;base de datos de más de 600 mil noticias chilenas&lt;/a&gt;, con su texto completo, y quiero empezar a sacarle más provecho. Por ejemplo, saber si noticias que hablan de ciertos temas son positivas o negativas (sentimiento), o simplemente clasificar de manera automatizada las noticias para separar las de política y economía de las de deportes y farándula.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Crea tu propio asistente de programación en R con inteligencia artificial usando el paquete {pal}</title>
      <link>http://localhost:4321/blog/pal_asistentes_llm/</link>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/pal_asistentes_llm/</guid>
      <description>&lt;p&gt;El paquete &#xA;&lt;a href=&#34;https://simonpcouch.github.io/pal/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;{pal}&lt;/code&gt;&lt;/a&gt; te permite crear &lt;em&gt;asistentes&lt;/em&gt; para programar en R, potenciados por modelos de lenguaje (LLM). La utilidad de estos asistentes es que pueden ayudarte a realizar tareas rápidamente a partir de tu código de R, o incluso a partir de un texto que describa lo que quieres hacer.&lt;/p&gt;&#xA;&lt;p&gt;En este post te enseño a crear y usar asistentes de &lt;code&gt;{pal}&lt;/code&gt; para dos tareas que realizo frecuentemente: &lt;strong&gt;describir lo que hace un código de R&lt;/strong&gt;, y &lt;strong&gt;traducir una instrucción a código de &lt;code&gt;{dplyr}&lt;/code&gt;&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Resumir textos usando modelos de lenguaje (LLM) locales en R</title>
      <link>http://localhost:4321/blog/resumir_texto_llm/</link>
      <pubDate>Fri, 06 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/resumir_texto_llm/</guid>
      <description>&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e0def4;background-color:#232136;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;library&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;dplyr&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;library&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;readr&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e0def4;background-color:#232136;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;url_datos&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#f6c177&#34;&gt;&amp;#34;https://raw.githubusercontent.com/bastianolea/prensa_chile/refs/heads/main/datos/prensa_datos_muestra.csv&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;noticias&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ea9a97&#34;&gt;read_csv2&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;url_datos&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;noticias_muestra&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ea9a97&#34;&gt;noticias&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;|&amp;gt;&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ea9a97&#34;&gt;slice_sample&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;n&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f6c177&#34;&gt;20&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;noticias_muestra&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e0def4;background-color:#232136;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;library&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;mall&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;library&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;stringr&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;library&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;beepr&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e0def4;background-color:#232136;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;llm_use&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f6c177&#34;&gt;&amp;#34;ollama&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#f6c177&#34;&gt;&amp;#34;llama3.1:8b&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;noticias_muestra_resumen&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ea9a97&#34;&gt;noticias_muestra&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;|&amp;gt;&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#ea9a97&#34;&gt;llm_summarize&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;paste&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;titulo&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#ea9a97&#34;&gt;cuerpo&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;|&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ea9a97&#34;&gt;str_trunc&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f6c177&#34;&gt;3000&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#ea9a97&#34;&gt;side&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f6c177&#34;&gt;&amp;#34;center&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;),&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#ea9a97&#34;&gt;max_words&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f6c177&#34;&gt;25&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#ea9a97&#34;&gt;pred_name&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f6c177&#34;&gt;&amp;#34;resumen&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;,&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#ea9a97&#34;&gt;additional_prompt&lt;/span&gt; &lt;span style=&#34;color:#908caa&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f6c177&#34;&gt;&amp;#34;Redacta el resumen de la idea principal de la noticia en español, y en un solo párrafo.&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;beep&lt;/span&gt;&lt;span style=&#34;color:#908caa&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.7 minutos&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e0def4;background-color:#232136;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ea9a97&#34;&gt;noticias_muestra_resumen&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Predecir género a partir de nombres usando un modelo de lenguaje en R</title>
      <link>http://localhost:4321/blog/genero_nombres_llm/</link>
      <pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/genero_nombres_llm/</guid>
      <description>&lt;p&gt;&#xA;&lt;a href=&#34;https://bastianolea.rbind.io/blog/introduccion_llm_mall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hace poco&lt;/a&gt; conocí &#xA;&lt;a href=&#34;https://mlverse.github.io/mall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;el paquete &lt;code&gt;{mall}&lt;/code&gt;&lt;/a&gt;, que facilita mucho el uso de un un modelo de lenguaje (LLM) local como una herramienta cotidiana para el análisis y procesamiento de datos.&lt;/p&gt;&#xA;&lt;p&gt;El paquete incluye varias funciones para usar un modelo LLM local en las columnas de un dataframe. &lt;code&gt;{mall}&lt;/code&gt; te puede ayudar a :&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;clasificar el contenido de una variable&lt;/li&gt;&#xA;&lt;li&gt;resumir textos&lt;/li&gt;&#xA;&lt;li&gt;extraer sentimiento a partir del texto&lt;/li&gt;&#xA;&lt;li&gt;extraer información desde el texto&lt;/li&gt;&#xA;&lt;li&gt;confirmar si algo es verdadero o falso a partir de un texto&lt;/li&gt;&#xA;&lt;li&gt;y también a aplicar cualquier &lt;em&gt;prompt&lt;/em&gt; a una variable.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Recientemente lo usé para un caso real, donde tenía una columna de casi 2.000 nombres, y necesitaba asignarle un género a cada una de estas personas, solamente a partir de sus nombres y apellidos.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Usar un modelo de lenguaje local (LLM) para analizar texto en R</title>
      <link>http://localhost:4321/blog/introduccion_llm_mall/</link>
      <pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/blog/introduccion_llm_mall/</guid>
      <description>&lt;p&gt;&#xA;&lt;a href=&#34;https://mlverse.github.io/mall/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Recientemente se lanzó el paquete &lt;code&gt;{mall}&lt;/code&gt;,&lt;/a&gt; que facilita el uso de un LLM &lt;em&gt;(large language model)&lt;/em&gt; o modelo de lenguaje de gran tamaño para analizar texto con IA en un dataframe. Esto significa que, para cualquier dataframe que tengamos, podemos aplicar un modelo de IA a una de sus columnas y recibir sus resultados en una columna nueva.&lt;/p&gt;&#xA;&lt;p&gt;Para poder hacer ésto, primero necitamos tener un modelo LLM instalado localmente en nuestra computadora. Para eso, &#xA;&lt;a href=&#34;https://ollama.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tenemos que instalar Ollama&lt;/a&gt;, y ejecutar la aplicación. Ollama tiene que estar abierto para poder proveer del modelo a nuestra sesión de R.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
